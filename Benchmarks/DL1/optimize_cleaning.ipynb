{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study on (tailcut) cleaning optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- This benchmark might not be optimal\n",
    "- It could use the prepared file from `Preparation/integration_prep.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to define a benchmark to optimise cleaning independently of any reconstruction that would come **after**.    \n",
    "This to avoid optimising the cleaning as a function of the whole reconstruction as:   \n",
    "- it can be tedious (you have to loop over the whole reconstruction)    \n",
    "- optimising cleaning before optimising the later part of the reconstruction might end up in reaching a cleaning well adapted to the reconstruction method chosen a priori but not good in absolute. (then a different/better reconstruction might end-up showing worst results)\n",
    "\n",
    "\n",
    "This benchmark uses the the ground thruth image in photo-electron from MC simulations by computing the distance between the cleaned image and the ground truth as a function of cleaning method/parameters and finding the minimum of this distance (average on many events).\n",
    "\n",
    "This also allow to study the cleaning as a function of event info (such as energy, signal amplitude... )\n",
    "\n",
    "Of course, this supposes that the calibration has been previously optimised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctapipe.io import event_source\n",
    "from ctapipe.utils import datasets\n",
    "from ctapipe.calib import CameraCalibrator\n",
    "from ctapipe.image import tailcuts_clean, dilate\n",
    "from ctapipe.visualization import CameraDisplay\n",
    "from ctapipe.instrument import CameraGeometry\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import poisson\n",
    "import os\n",
    "from ctapipe.utils import get_dataset_path\n",
    "import copy\n",
    "import astropy.units as u\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_image(camera_geometry, image, cleaning, **cleaning_params):\n",
    "    \"\"\"\n",
    "    Apply a cleaning method to a calibrated event\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply image cleaning\n",
    "    cleanmask = cleaning(camera_geometry, image,\n",
    "                               **cleaning_params\n",
    "                               )\n",
    "\n",
    "    cleaned_image = copy.deepcopy(image)\n",
    "    cleaned_image[~cleanmask] = 0\n",
    "\n",
    "    return cleaned_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_accuracy(cleaned_image, true_image):\n",
    "    \"\"\"\n",
    "    compute a single number giving the cleaning accuracy (lower is better)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.linalg.norm(cleaned_image - true_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tailcut_cleaning_accuracy(camera_geometry, image, true_image, picture_threshold, boundary_threshold):\n",
    "    \"\"\"\n",
    "    Apply tailcut cleaning and compute cleaning accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    tailcut_params = {'picture_thresh':picture_threshold,\n",
    "                  'boundary_thresh':boundary_threshold,\n",
    "                  'keep_isolated_pixels':False,\n",
    "                  'min_number_picture_neighbors':1,\n",
    "                 }\n",
    "\n",
    "    cleaned_image = get_cleaned_image(camera_geometry, image, tailcuts_clean, **tailcut_params)\n",
    "\n",
    "    diff = cleaning_accuracy(cleaned_image, true_image)\n",
    "    \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_name = 'FlashCam'\n",
    "tel_ids_with_camera_name = [tel_id for tel_id in source.subarray.tel.keys() if source.subarray.tel[tel_id].camera.camera_name == camera_name]\n",
    "tel_ids_with_camera_name\n",
    "event.r0.tels_with_data.intersection(tel_ids_with_camera_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tailcut_cleaning_analyse(source, camera_name, picture_threshold=[2, 10, 5], min_boundary_threshold=0):\n",
    "    \"\"\"\n",
    "    source: event_source object\n",
    "    picture_threshold: list of [min, max, number of steps]\n",
    "    \"\"\"\n",
    "    ptmin, ptmax, ptnumber = picture_threshold\n",
    "    pt = np.linspace(ptmin, ptmax, ptnumber)\n",
    "    \n",
    "    picture_threshold = np.empty((ptnumber,ptnumber))\n",
    "    boundary_threshold = np.empty((ptnumber,ptnumber))\n",
    "    for i in range(ptnumber):\n",
    "        picture_threshold[i] = pt\n",
    "        boundary_threshold.T[i] = np.linspace(min_boundary_threshold, pt[i], ptnumber)\n",
    "        \n",
    "    all_diff = []\n",
    "    event_energy = []\n",
    "    event_dl1_amplitude = []\n",
    "    event_multiplicity = []\n",
    "    \n",
    "    tel_ids_with_camera_name = [tel_id for tel_id in source.subarray.tel.keys() if source.subarray.tel[tel_id].camera.camera_name == camera_name]\n",
    "    geom = source.subarray.tel[tel_ids_with_camera_name[0]].camera.geometry\n",
    "    \n",
    "    for event in source:\n",
    "        cal(event)\n",
    "        diff = np.zeros((ptnumber,ptnumber))\n",
    "        event_energy.append(event.mc.energy.to(u.TeV).value)\n",
    "        event_multiplicity.append(len(event.r0.tels_with_data))\n",
    "        for i in range(ptnumber):\n",
    "            for j in range(ptnumber):\n",
    "                pt = picture_threshold[i, j]\n",
    "                bt = boundary_threshold[i, j]\n",
    "                for tel_id in event.r0.tels_with_data.intersection(tel_ids_with_camera_name):\n",
    "                    image = event.dl1.tel[tel_id].image\n",
    "                    true_image = event.mc.tel[tel_id].true_image\n",
    "                    d = tailcut_cleaning_accuracy(geom, image, true_image, pt, bt)\n",
    "                    diff[i,j]+=d\n",
    "        all_diff.append(diff)\n",
    "        \n",
    "        amp = 0\n",
    "        for tel_id in event.r0.tels_with_data:\n",
    "            amp += event.dl1.tel[tel_id].image[0].sum()\n",
    "        event_dl1_amplitude.append(amp)\n",
    "        \n",
    "    all_diff = np.array(all_diff)\n",
    "    \n",
    "    event_info = {'event_energy': np.array(event_energy) * u.TeV, \n",
    "                  'event_multiplicity': np.array(event_multiplicity),\n",
    "                  'event_dl1_amplitude': np.array(event_dl1_amplitude)}\n",
    "    \n",
    "    return np.array([picture_threshold, boundary_threshold]), all_diff, event_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(thresholds, all_diff):\n",
    "    index = np.unravel_index(all_diff.sum(axis=0).argmin(), all_diff.sum(axis=0).shape)\n",
    "    return thresholds[0][index], thresholds[1][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cleaning_analysis(thresholds, all_diff, ax=None, **kwargs):\n",
    "    \n",
    "    ax = plt.gca() if ax is None else ax\n",
    "    \n",
    "    x = thresholds[0].ravel()\n",
    "    y = thresholds[1].ravel()\n",
    "    z = all_diff.sum(axis=0).ravel()\n",
    "    im = ax.tricontourf(x,y,z, 20)\n",
    "    ax.set_xlabel('picture threshold')\n",
    "    ax.set_ylabel('boundary threshold')\n",
    "    plt.colorbar(im)\n",
    "    # ax.axis('equal')\n",
    "    print(\"Best thresholds = \", find_best_threshold(thresholds, all_diff))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_all_cameras(filename, \n",
    "                        cal,\n",
    "                       max_events = None,\n",
    "                       **kwargs_tailcut_analysis):\n",
    "    \n",
    "    source = event_source(filename, back_seekable=True)\n",
    "    \n",
    "    source.max_events = max_events\n",
    "    \n",
    "    cam_dict = set([source.subarray.tel[tel_id].camera.camera_name for tel_id in source.subarray.tel.keys()])\n",
    "\n",
    "    for cam_name in cam_dict:     \n",
    "        thresholds, all_diff, event_info = tailcut_cleaning_analyse(source, \n",
    "                                                                    cam_name,\n",
    "                                                                    picture_threshold=[2, 20, 10],\n",
    "                                                                    min_boundary_threshold=-10 )\n",
    "        cam_dict[cam_id] = find_best_threshold(thresholds, all_diff)\n",
    "        print(\"Best thresholds for camera {0} are: {1}\".format(cam_id, find_best_threshold(thresholds, all_diff)))\n",
    "            \n",
    "    return cam_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_dir = '/Users/thomasvuillaume/Work/CTA/Data/DL0/Simtel/'\n",
    "gamma_diffuse = 'gamma_20deg_0deg_run100___cta-prod3-lapalma3-2147m-LaPalma_cone10.simtel.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(input_dir, gamma_diffuse)\n",
    "source = event_source(input_url = filename, back_seekable=True)\n",
    "source.max_events = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctapipe.calib.camera.calibrator import NeighborPeakWindowSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = CameraCalibrator(subarray=source.subarray) #image_extractor = NeighborPeakWindowSum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event=next(iter(source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise simple cleaning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event.r0.tels_with_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tailcut_params = {'picture_thresh':4,\n",
    "                  'boundary_thresh':1,\n",
    "                  'keep_isolated_pixels':False,\n",
    "                  'min_number_picture_neighbors':1,\n",
    "                 }\n",
    "cal(event)\n",
    "\n",
    "for tel_id in event.r0.tels_with_data:\n",
    "    image = event.dl1.tel[tel_id].image\n",
    "    camera_geometry = source.subarray.tels[tel_id].camera.geometry\n",
    "    cleaned_image = get_cleaned_image(camera_geometry, image, tailcuts_clean, **tailcut_params)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(35,10))\n",
    "    print(tel_id)\n",
    "    CameraDisplay(source.subarray.tel[tel_id].camera.geometry, event.dl1.tel[tel_id].image, ax=axes[0])\n",
    "    axes[0].set_title(\"Calibrated image\")\n",
    "    CameraDisplay(source.subarray.tel[tel_id].camera.geometry, cleaned_image, ax=axes[1])\n",
    "    axes[1].set_title(\"Cleaned image\")\n",
    "    CameraDisplay(source.subarray.tel[tel_id].camera.geometry, event.mc.tel[tel_id].true_image, ax=axes[2])\n",
    "    axes[2].set_title(\"True image\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tailcut_params = {'picture_thresh':2,\n",
    "                  'boundary_thresh':1,\n",
    "                  'keep_isolated_pixels':False,\n",
    "                  'min_number_picture_neighbors':1,\n",
    "                 }\n",
    "cal(event)\n",
    "\n",
    "for tel_id in event.r0.tels_with_data:\n",
    "    geom = source.subarray.tel[tel_id].camera.geometry\n",
    "    image = event.dl1.tel[tel_id].image.copy()\n",
    "    pulse_time = event.dl1.tel[tel_id].peak_time.copy()\n",
    "    cleaned_image = get_cleaned_image(geom, image, tailcuts_clean, **tailcut_params)\n",
    "#     pulse_time -= np.median(pulse_time)\n",
    "#     print(pulse_time.mean())\n",
    "#     image[pulse_time>20] = 0\n",
    "    m = image.max()\n",
    "    weighted_image = image/(1+pulse_time)\n",
    "    weighted_image *= m/weighted_image.max()\n",
    "    pixels = tailcuts_clean(geom, weighted_image, **tailcut_params)\n",
    "    image[~pixels] = 0\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(35,10))\n",
    "    print(tel_id)\n",
    "    display = CameraDisplay(geom, image, ax=axes[0])\n",
    "    axes[0].set_title(\"Calibrated image\")\n",
    "    display.add_colorbar(ax=axes[0])\n",
    "    display = CameraDisplay(geom, cleaned_image, ax=axes[1])\n",
    "    axes[1].set_title(\"Cleaned image\")\n",
    "    display.add_colorbar(ax=axes[1])\n",
    "    display = CameraDisplay(geom, event.mc.tel[tel_id].true_image, ax=axes[2])\n",
    "    display.add_colorbar()\n",
    "    axes[2].set_title(\"True image\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = event.dl1.tel[tel_id].image\n",
    "true_image = event.mc.tel[tel_id].true_image\n",
    "tailcut_cleaning_accuracy(geom, image, true_image, 8, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds, all_diff, event_info = \\\n",
    "tailcut_cleaning_analyse(source,\n",
    "                         'LSTCam',\n",
    "                         picture_threshold=[2, 20, 10],\n",
    "                         min_boundary_threshold=-10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thresholds.shape, all_diff.shape)\n",
    "print(event_info.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the result and finding the best tailcut thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,10))\n",
    "ax = plot_cleaning_analysis(thresholds, all_diff, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One can also make analysis as a function of event info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By total event amplitude (in p.e.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(event_info['event_dl1_amplitude'], log=True, bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = event_info['event_dl1_amplitude'] > 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_cleaning_analysis(thresholds, all_diff[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or by event energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = event_info['event_energy'].value < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_cleaning_analysis(thresholds, all_diff[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally one can make an analysis to find the best threshold for each camera type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresh = analyse_all_cameras(filename, \n",
    "                                  max_events=30, \n",
    "                                  **{'picture_threshold': [2, 14, 10], \n",
    "                                     'min_boundary_threshold':-4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
